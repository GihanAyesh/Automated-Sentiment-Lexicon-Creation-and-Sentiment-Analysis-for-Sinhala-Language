{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Rir7veF_KHhw","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x\n","first_time = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xPrx8AuqU805","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"bb007a15-c747-4870-d083-dd8180ebf909","executionInfo":{"status":"ok","timestamp":1592216796248,"user_tz":-330,"elapsed":3532,"user":{"displayName":"Lahiru Senevirathne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzF3KfxeuLmDoDB90oNXQ5_ivLn8-Ar4kecdc=s64","userId":"12627549003426465017"}}},"source":["if(first_time):\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","import numpy as np\n","import pandas as pd\n","import datetime\n","from random import randint\n","from gensim.models import word2vec\n","from sklearn.model_selection import train_test_split\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n","from gensim.models.fasttext import FastText"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KZmJQUEVY9Lw","colab_type":"text"},"source":["/content/drive/My Drive/University/FYP/Sentiment Analysis/Research by Isuru/Word_Embedding"]},{"cell_type":"code","metadata":{"id":"HjLmM5uuY-4e","colab_type":"code","colab":{}},"source":["folder_path = '/content/drive/My Drive/University/FYP/Sentiment Analysis/Implementation/'\n","fasttext_model_path = folder_path + 'word_embedding/fasttext/commen_docid_removed300_5'\n","dataset_path = folder_path + \"corpus/analyzed/lankadeepa_tagged_2.csv\"\n","data_vectors_path = folder_path + 'corpus/analyzed/vectors/'\n","RNN_path = \"Sentiment Analysis/Sentiment_Tagger_Recreation/RNN/\"\n","log_dir_path = folder_path + RNN_path + \"logs/from_fasttext/\"\n","model_save_path = folder_path + RNN_path + \"models/from_fasttext/pretrained_lstm.ckpt\"\n","\n","num_features = 300\n","max_sentence_length = 50\n","batchSize = 24\n","lstmUnits = 64\n","numClasses = 2\n","iterations = 30000\n","\n","labels = tf.placeholder(tf.int32, [batchSize, numClasses])\n","data = tf.placeholder(tf.float32, [batchSize, max_sentence_length, num_features])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qv8b74RIaAlc","colab_type":"code","colab":{}},"source":["def convert_to_vectors():\n","    comments = pd.read_csv(dataset_path, \";\")\n","    train_data, test_data = train_test_split(comments, test_size=0.2, random_state=0)\n","    train_data_vectors, train_data_labels = comments_to_vectors(train_data)\n","    test_data_vectors, test_data_labels = comments_to_vectors(test_data)\n","\n","    np.save(data_vectors_path + 'from_fasttext/train_data_vectors.npy', train_data_vectors)\n","    np.save(data_vectors_path + 'from_fasttext/train_data_labels.npy', train_data_labels)\n","    np.save(data_vectors_path + 'from_fasttext/test_data_vectors.npy', test_data_vectors)\n","    np.save(data_vectors_path + 'from_fasttext/test_data_labels.npy', test_data_labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1_k3Ai0wACoj","colab_type":"code","colab":{}},"source":["def load_vectors():\n","    train_data_vectors = np.load(data_vectors_path + 'from_fasttext/train_data_vectors.npy')\n","    train_data_labels = np.load(data_vectors_path + 'from_fasttext/train_data_vectors.npy')\n","    test_data_vectors = np.load(data_vectors_path + 'from_fasttext/train_data_vectors.npy')\n","    test_data_labels = np.load(data_vectors_path + 'from_fasttext/train_data_vectors.npy')\n","    \n","    return train_data_vectors, train_data_labels, test_data_vectors, test_data_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"N3YnY6OFZuvy","colab_type":"code","colab":{}},"source":["def get_sentence_vector(model, sentence):\n","    sentence_vector = np.zeros([max_sentence_length, num_features])\n","    counter = 0\n","    index2word_set = set(model.wv.index2word)\n","    for word in sentence.split():\n","        if word in index2word_set:\n","            sentence_vector[counter] = model[word]\n","            counter += 1\n","            if (counter == max_sentence_length):\n","                break\n","        else:\n","            print(\"word not in word2vec model: \" + word+\"Counter : \",counter)\n","    return sentence_vector\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SiW6RvxwZyCf","colab_type":"code","colab":{}},"source":["def comments_to_vectors(data):\n","    model = word2vec.Word2Vec.load(fasttext_model_path)\n","    # model = FastText.load_fasttext_format(fasttext_model_name)\n","    comment_vectors = []\n","    comment_labels = []\n","    for comment in data[\"comment\"]:\n","        comment_vectors.append(get_sentence_vector(model, comment))\n","    for label in data[\"label\"]:\n","        if label == \"POSITIVE\":\n","            comment_labels.append([0, 1])\n","        else:\n","            comment_labels.append([1, 0])\n","    return np.array(comment_vectors), comment_labels"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O6nNeTyQBKng","colab_type":"code","colab":{}},"source":["def get_batch(size, data, label):\n","    batch_data = np.empty((size, max_sentence_length, num_features), dtype=float)\n","    batch_label = []\n","    for i in range(size):\n","        random_int = randint(0, len(data) - 1)\n","        batch_data[i] = data[random_int]\n","        batch_label.append(label[random_int])\n","    return batch_data, batch_label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ay_GNuT0BNss","colab_type":"code","colab":{}},"source":["def get_batch_order(size, data, label, batch_no):\n","    batch_data = data[batch_no * size : (batch_no + 1) * size]\n","    batch_label = label[batch_no * size : (batch_no + 1) * size]\n","    return batch_data, batch_label"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dtYCbmRMBTqI","colab_type":"code","colab":{}},"source":["def neural_network_model():\n","    lstm_cell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n","\n","    lstm_cell = tf.contrib.rnn.DropoutWrapper(cell=lstm_cell, output_keep_prob=0.75)\n","    value, _ = tf.nn.dynamic_rnn(lstm_cell, data, dtype=tf.float32)\n","\n","    weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n","    bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n","    value = tf.transpose(value, [1, 0, 2])\n","    last = tf.gather(value, int(value.get_shape()[0]) - 1)\n","    prediction = (tf.matmul(last, weight) + bias)\n","\n","    correct_prediction = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","    prediction_values = tf.argmax(prediction, 1)\n","\n","    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n","    optimizer = tf.train.AdamOptimizer().minimize(loss)\n","\n","    return loss, accuracy, prediction_values, optimizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bKmY2Zj3Bchx","colab_type":"code","colab":{}},"source":["def train_neural_network(loss, accuracy, optimizer, train_data, train_labels):\n","    sess = tf.InteractiveSession()\n","    saver = tf.train.Saver()\n","    sess.run(tf.global_variables_initializer())\n","\n","    tf.summary.scalar('Loss', loss)\n","    tf.summary.scalar('Accuracy', accuracy)\n","    merged = tf.summary.merge_all()\n","    logdir = log_dir_path + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n","    writer = tf.summary.FileWriter(logdir, sess.graph)\n","\n","    for i in range(iterations):\n","        #Next Batch of reviews\n","        next_batch, next_batch_labels = get_batch(batchSize, train_data, train_labels)\n","        sess.run(optimizer, {data: next_batch, labels: next_batch_labels})\n","\n","        #Write summary to Tensorboard\n","        if (i % 50 == 0):\n","            summary = sess.run(merged, {data: next_batch, labels: next_batch_labels})\n","            writer.add_summary(summary, i)\n","\n","        #Save the network every 10,000 training iterations\n","        if (i % 9999 == 0 and i != 0):\n","            save_path = saver.save(sess, model_save_path , global_step=i)\n","            print(\"saved to %s\" % save_path)\n","    writer.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DNTTHx5wCVbH","colab_type":"code","colab":{}},"source":["def measure_neural_network(accuracy, prediction_values, test_data, test_labels):\n","    sess = tf.InteractiveSession()\n","    saver = tf.train.Saver()\n","    saver.restore(sess, tf.train.latest_checkpoint(model_save_path))\n","\n","    overall_accuracy = 0\n","    all_predictions = []\n","    test_iterations = 80\n","    for i in range(test_iterations):\n","        next_batch, next_batch_labels = get_batch_order(batchSize, test_data, test_labels, i)\n","        accuracy_this_batch = (sess.run(accuracy, {data: next_batch, labels: next_batch_labels})) * 100\n","        predictions_this_batch = sess.run(prediction_values, {data: next_batch, labels: next_batch_labels})\n","        overall_accuracy = overall_accuracy + accuracy_this_batch\n","        all_predictions = all_predictions + predictions_this_batch.tolist()\n","        print(\"Accuracy for this batch:\", accuracy_this_batch)\n","\n","    true_labels = tf.argmax(test_labels, 1).eval()\n","    precision = precision_score(true_labels.tolist()[0:batchSize * test_iterations], all_predictions)\n","    f1 = f1_score(true_labels.tolist()[0:batchSize * test_iterations], all_predictions)\n","    recall = recall_score(true_labels.tolist()[0:batchSize * test_iterations], all_predictions)\n","    overall_accuracy = overall_accuracy / (test_iterations * 100)\n","    print(confusion_matrix(true_labels.tolist()[0:batchSize * test_iterations], all_predictions).ravel())\n","\n","    return overall_accuracy, precision, recall, f1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7FdXGN69Pkxh","colab_type":"text"},"source":["# Main"]},{"cell_type":"code","metadata":{"id":"rLjA0lkYNvtI","colab_type":"code","colab":{}},"source":["# convert_to_vectors()\n","train_data_vectors, train_data_labels, test_data_vectors, test_data_labels = load_vectors()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1qvvn-1sNxa4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":530},"outputId":"fc0b8b71-66a0-4546-a876-6aee38640832","executionInfo":{"status":"ok","timestamp":1592216799428,"user_tz":-330,"elapsed":6449,"user":{"displayName":"Lahiru Senevirathne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzF3KfxeuLmDoDB90oNXQ5_ivLn8-Ar4kecdc=s64","userId":"12627549003426465017"}}},"source":["print(\"Running tesnsorflow simulation.....\")\n","loss, accuracy, prediction_values, optimizer = neural_network_model()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Running tesnsorflow simulation.....\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From <ipython-input-11-9adbba21453d>:2: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From <ipython-input-11-9adbba21453d>:5: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From <ipython-input-11-9adbba21453d>:17: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","\n","Future major versions of TensorFlow will allow gradients to flow\n","into the labels input on backprop by default.\n","\n","See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TWLxSdU0N325","colab_type":"code","outputId":"d56c54a5-fe6c-4043-9df5-3d9aaa39b14b","executionInfo":{"status":"error","timestamp":1592216805657,"user_tz":-330,"elapsed":2011,"user":{"displayName":"Lahiru Senevirathne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzF3KfxeuLmDoDB90oNXQ5_ivLn8-Ar4kecdc=s64","userId":"12627549003426465017"}},"colab":{"base_uri":"https://localhost:8080/","height":326}},"source":["train_neural_network(loss, accuracy, optimizer, train_data_vectors, train_data_labels)"],"execution_count":16,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-2cc53c45c0d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_neural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-1f8d42c25641>\u001b[0m in \u001b[0;36mtrain_neural_network\u001b[0;34m(loss, accuracy, optimizer, train_data, train_labels)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#Next Batch of reviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnext_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_batch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnext_batch_labels\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m#Write summary to Tensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1157\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (24, 50, 300) for Tensor 'Placeholder:0', which has shape '(24, 2)'"]}]},{"cell_type":"code","metadata":{"id":"f5rirxnEN6rS","colab_type":"code","colab":{}},"source":["accuracy, precision, recall, f1 = measure_neural_network(accuracy, prediction_values, test_data_vectors, test_data_labels)\n","print(\"Accuracy: \", accuracy)\n","print(\"Precision: \", precision)\n","print(\"Recall: \", recall)\n","print(\"F1 Score: \", f1)"],"execution_count":0,"outputs":[]}]}