{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"cnn_rnn_with_preprocess_multiclass.ipynb","provenance":[{"file_id":"153374pBL1OZuAJMWKK_ae0D9_DUq4P0P","timestamp":1590420423516}],"collapsed_sections":["3zR8-aK009p9","lrmGuYXf82E_","hx80tScO_ddi","Pt3TZsP84gRK","k7QWHo7RBFYw","P5nll2IhjLhr","WC0ZRhKe5a6C","u4DuyDZMkcE3","B6CXqtIDR4jS"]},"environment":{"name":"tf2-2-2-gpu.2-2.m50","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/tf2-2-2-gpu.2-2:m50"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"t6nTBbEWxpxA"},"source":["# References\n","https://github.com/ultimate010/crnn \n","{Combination of Convolutional and Recurrent Neural Network for Sentiment Analysis of Short Texts}\n","https://keras.io/examples/imdb_bidirectional_lstm/"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3zR8-aK009p9"},"source":["# Folder Paths"]},{"cell_type":"code","metadata":{"id":"dbSiWEihH0zu","colab_type":"code","colab":{},"cellView":"both","executionInfo":{"status":"ok","timestamp":1596261722655,"user_tz":-330,"elapsed":1466,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["Host = \"colab\" #@param [\"colab\", \"AWS\"]\n","Account = \"colab_datapirates\" #@param[\"colab_datapirates\", \"colab_lahiru_cse\", \"colab_lahiru_personal\"]\n","embedding_size = 300 #@param [50, 150, 200, 250, 300, 350, 400, 450, 500]\n","embedding_type = \"fasttext\" #@param [\"fasttext\",\"word2vec\"]\n","experiment_no = \"113\" #@param [] {allow-input: true}\n","model_name = \"stacked_LSTM_3\" #@param [\"stacked_LSTM_3\"] {allow-input: true}"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gWPD3dgEqB5d","colab":{},"executionInfo":{"status":"ok","timestamp":1596261724562,"user_tz":-330,"elapsed":3347,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["\n","folder_path = None\n","if (Host == \"AWS\" ):\n","  folder_path = \"../../../\"\n","else:\n","  if (Account == \"colab_datapirates\"):\n","    folder_path = \"/content/drive/My Drive/FYP/Sentiment Analysis/Implementation/\"\n","  if (Account == \"colab_lahiru_cse\"):\n","      folder_path =  '/content/drive/My Drive/University/FYP/Sentiment Analysis/Implementation/'\n","  if (Account == \"colab_lahiru_personal\"):\n","      folder_path =  '/content/drive/My Drive/University/FYP/Sentiment Analysis/Implementation/'\n","\n","lankadeepa_data_path = folder_path + 'corpus/new/preprocess_from_isuru/lankadeepa_tagged_comments.csv'\n","gossip_lanka_data_path = folder_path + 'corpus/new/preprocess_from_unicode_values/gossip_lanka_tagged_comments.csv'\n","\n","context = 5\n","word_embedding_path = folder_path + \"word_embedding/\"+embedding_type+\"/source2_data_from_gosspiLanka_and_lankadeepa/\"+str(embedding_size)+\"/\"+embedding_type+\"_\"+str(embedding_size)+\"_\"+str(context)\n","word_embedding_keydvectors_path = folder_path + \"word_embedding/\"+embedding_type+\"/source2_data_from_gosspiLanka_and_lankadeepa/\"+str(embedding_size)+\"/keyed_vectors/keyed.kv\"\n","embedding_matrix_path = folder_path + 'Sentiment Analysis/CNN RNN/embedding_matrix/'+embedding_type+'_lankadeepa_gossiplanka_'+str(embedding_size)+'_'+str(context)"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"e5mAlQD5-2U4","colab":{},"executionInfo":{"status":"ok","timestamp":1596261724563,"user_tz":-330,"elapsed":3336,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["experiment_name = folder_path + \"Sentiment Analysis/CNN RNN/experiments/\" +str(experiment_no) + \"_\"+ model_name +\"_\"+embedding_type+\"_\"+str(embedding_size)+\"_\"+str(context)\n","model_save_path = folder_path + \"Sentiment Analysis/CNN RNN/saved_models/\"+str(experiment_no)+\"_weights_best_\"+model_name+\"_\"+embedding_type+\"_\"+str(experiment_no)+\".hdf5\""],"execution_count":57,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0BYvE-D5QAc0"},"source":["# Dependencies"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gZ9YDtD6qn4t","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1596261724564,"user_tz":-330,"elapsed":3315,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}},"outputId":"4be30f5b-c32c-4532-b3f6-0e79e8a870fe"},"source":["from __future__ import print_function\n","if (Host == \"colab\"):\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","import collections\n","import pickle\n","import re\n","import random\n","import sys\n","import os \n","import time\n","\n","import gensim\n","from gensim.models.keyedvectors import KeyedVectors\n","from gensim.models.fasttext import FastText\n","from gensim.models import word2vec\n","\n","from sklearn.model_selection import train_test_split,cross_val_score, cross_val_predict, KFold\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix,precision_recall_fscore_support\n","\n","import pandas as pd\n","import numpy as np\n","from numpy import array\n","from numpy import asarray\n","from numpy import zeros\n","from numpy import cumsum\n","\n","import keras\n","from keras import backend as K\n","from keras.models import Sequential,Model,load_model\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.layers import Dropout, Activation, Flatten, \\\n","    Embedding, Convolution1D, MaxPooling1D, AveragePooling1D, \\\n","    Input, Dense, merge, Add,TimeDistributed, Bidirectional,SpatialDropout1D\n","from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n","from keras.regularizers import l2, l1_l2\n","from keras.constraints import maxnorm\n","from keras import callbacks\n","from keras.utils import generic_utils\n","from keras.optimizers import Adadelta\n","from keras.callbacks import ModelCheckpoint,EarlyStopping\n","\n","import matplotlib.image  as mpimg\n","import matplotlib.pyplot as plt\n","\n"],"execution_count":58,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xXiAlHRZ7X_p"},"source":["# Load Data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GqqHP9rwpbdt","colab":{},"executionInfo":{"status":"ok","timestamp":1596261724565,"user_tz":-330,"elapsed":3294,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["lankadeepa_data = pd.read_csv(lankadeepa_data_path)[:9059]\n","gossipLanka_data = pd.read_csv(gossip_lanka_data_path)\n","gossipLanka_data = gossipLanka_data.drop(columns=['Unnamed: 3'])"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qm-gaV94U4Ob","colab":{},"executionInfo":{"status":"ok","timestamp":1596261724566,"user_tz":-330,"elapsed":3280,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["all_data = pd.concat([lankadeepa_data,gossipLanka_data])"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Kxm16KdZVIWo","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1596261724567,"user_tz":-330,"elapsed":3267,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}},"outputId":"777b5caa-b74d-4ad8-a4d8-798d18d33357"},"source":["all_data['label'].value_counts()"],"execution_count":61,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2    7665\n","4    3080\n","3    2403\n","5    1911\n","Name: label, dtype: int64"]},"metadata":{"tags":[]},"execution_count":61}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Shq4w6GcqbIq"},"source":["# preprocess Data"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"IHqkf0XG8dqL"},"source":["## Preprocessing 1"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"y9ynks11qZ-e","colab":{},"executionInfo":{"status":"ok","timestamp":1596261724568,"user_tz":-330,"elapsed":3239,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["# edit this later \n","def text_preprocessing(train_data,test_data):\n","  train_data_texts = train_data['comment']\n","  train_data_labels = train_data['label']\n","  test_data_texts = test_data['comment']\n","  test_data_labels = test_data['label']\n","\n","\n","  comment_texts = []\n","  comment_labels = []\n","\n","  train_text = []\n","  test_text = []\n","  train_labels=[]\n","  test_labels=[]\n","\n","  for label in train_data_labels:\n","    if label == \"POSITIVE\":\n","      train_labels.append(1)\n","    else:\n","      train_labels.append(0)\n","  comment_labels.append(train_labels)\n","\n","  for label in test_data_labels:\n","    if label == \"POSITIVE\":\n","      test_labels.append(1)\n","    else:\n","      test_labels.append(0)\n","  comment_labels.append(test_labels)\n","  \n","\n","  for comment in train_data_texts:\n","    lines = []\n","    try:\n","      words = comment.split()\n","      lines += words\n","    except:\n","      continue\n","    train_text.append(lines)\n","  comment_texts.append(train_text)\n","\n","  for comment in test_data_texts:\n","    lines = []\n","    try:\n","      words = comment.split()\n","      lines += words\n","    except:\n","      continue\n","    test_text.append(lines)\n","  comment_texts.append(test_text)\n","\n","\n","  return comment_texts,comment_labels\n","\n","# edit this later \n","def text_preprocessing_1(data):\n","  comments = data['comment']\n","  labels = data['label']\n","\n","  comments_splitted = []\n","  labels_encoded = []\n","\n","  for label in labels:\n","    if label == \"POSITIVE\":\n","      labels_encoded.append(1)\n","    else:\n","      labels_encoded.append(0)\n","\n","  for comment in comments:\n","    lines = []\n","    try:\n","      words = comment.split()\n","      lines += words\n","    except:\n","      continue\n","    comments_splitted.append(lines)\n","  return comments_splitted,labels_encoded\n","\n","\n","def text_preprocessing_2(data):\n","  comments = data['comment']\n","  labels = data['label']\n","\n","  comments_splitted = []\n","\n","  for comment in comments:\n","    lines = []\n","    try:\n","      words = comment.split()\n","      lines += words\n","    except:\n","      continue\n","    comments_splitted.append(lines)\n","\n","  return comments_splitted,labels"],"execution_count":62,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"LdKgzrbd8Uy8"},"source":["## Preprocessing 2"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BZoOqtodrUY1","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596261724568,"user_tz":-330,"elapsed":3185,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}},"outputId":"81f65317-0ea8-4860-aaa9-c93e3db7fbe8"},"source":["comment_texts, comment_labels = text_preprocessing_2(all_data)\n","\n","# prepare tokenizer\n","\n","t = Tokenizer()\n","t.fit_on_texts(comment_texts)\n","vocab_size = len(t.word_index) + 1\n","print(vocab_size)"],"execution_count":63,"outputs":[{"output_type":"stream","text":["60316\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UMhZbzGur4kt","colab":{},"executionInfo":{"status":"ok","timestamp":1596261724569,"user_tz":-330,"elapsed":3164,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["encoded_docs = t.texts_to_sequences(comment_texts)"],"execution_count":64,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ho5NTzHtsKoN","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725596,"user_tz":-330,"elapsed":4172,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["max_length = len(max(encoded_docs, key=len))\n","padded_docs = pad_sequences(encoded_docs, maxlen=max_length)\n","\n","comment_labels = np.array(comment_labels)\n","padded_docs = np.array(padded_docs)"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gBRINFtdvEQS","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596261725597,"user_tz":-330,"elapsed":4154,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}},"outputId":"9797deea-4104-4942-939d-677e0c7aa9c5"},"source":["comment_labels = pd.get_dummies(comment_labels).values\n","print('Shape of label tensor:', comment_labels.shape)"],"execution_count":66,"outputs":[{"output_type":"stream","text":["Shape of label tensor: (15059, 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Drgv_J0ZUV8j","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725597,"user_tz":-330,"elapsed":4133,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["\n","X_train, X_test, y_train, y_test = train_test_split(padded_docs, comment_labels, test_size=0.2, random_state=0)\n"],"execution_count":67,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"91fqgdk67oaZ"},"source":["# Word Embedding"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sPm_9b6Y8EPi"},"source":["## Generate Embedding Metrix"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kOB0YKL-fNW5","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725598,"user_tz":-330,"elapsed":4119,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["def generate_embedding_metrix():\n","  if (embedding_type == 'fasttext'):\n","    word_embedding_model = FastText.load(word_embedding_path)\n","  else:\n","    word_embedding_model = word2vec.Word2Vec.load(word_embedding_path)\n","    \n","  word_vectors = word_embedding_model.wv\n","  word_vectors.save(word_embedding_keydvectors_path)\n","  word_vectors = KeyedVectors.load(word_embedding_keydvectors_path, mmap='r')\n","\n","  embeddings_index = dict()\n","  for word, vocab_obj in word_vectors.vocab.items():\n","    embeddings_index[word]=word_vectors[word]\n","\n","  # create a weight matrix for words in training docs\n","  embedding_matrix = zeros((vocab_size, embedding_size))\n","  for word, i in t.word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","      embedding_matrix[i] = embedding_vector\n","\n","  pickle.dump(embedding_matrix, open(embedding_matrix_path, 'wb'))\n","  return embedding_matrix"],"execution_count":68,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wVYEOwiN8H3s"},"source":["## Load Embedding Matrix"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YNSwoRM292-u","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725598,"user_tz":-330,"elapsed":4101,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["def load_word_embedding_atrix():\n","  f = open(embedding_matrix_path, 'rb')\n","  embedding_matrix= np.array(pickle.load(f))\n","  return embedding_matrix"],"execution_count":69,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lrmGuYXf82E_"},"source":["# Models"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hx80tScO_ddi"},"source":["## RNN(LSTM/GRU) model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"K9elMDrR_laX","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725599,"user_tz":-330,"elapsed":4085,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["def build_RNN_model():\n","    main_input = Input(shape=(maxlen, ), dtype='int32', name='main_input')\n","    embedding  = Embedding(max_features, embedding_dims,\n","                  weights=[embedding_matrix], input_length=maxlen,\n","                  name='embedding' ,trainable=False)(main_input)\n","\n","    embedding = Dropout(0.50)(embedding)\n","\n","    x = RNN(rnn_output_size)(embedding)\n","\n","    x = Dense(hidden_dims, activation='relu', init='he_normal',\n","              W_constraint = maxnorm(3), b_constraint=maxnorm(3),\n","              name='mlp')(x)\n","\n","    x = Dropout(0.10, name='drop')(x)\n","\n","    output = Dense(4, init='he_normal',\n","                   activation='softmax', name='output')(x)\n","\n","    model = Model(input=main_input, output=output)\n","\n","    print(model.summary())\n","    return model\n","\n","def build_stacked_RNN_model():\n","    main_input = Input(shape=(maxlen, ), dtype='int32', name='main_input')\n","    embedding  = Embedding(max_features, embedding_dims,\n","                  weights=[embedding_matrix], input_length=maxlen,\n","                  name='embedding' ,trainable=False)(main_input)\n","\n","    embedding = Dropout(0.50)(embedding)\n","\n","    x = RNN(rnn_output_size,return_sequences=True)(embedding)\n","    x = RNN(rnn_output_size)(x)\n","\n","    x = Dense(hidden_dims, activation='relu', init='he_normal',\n","              W_constraint = maxnorm(3), b_constraint=maxnorm(3),\n","              name='mlp')(x)\n","\n","    x = Dropout(0.10, name='drop')(x)\n","\n","    output = Dense(4, init='he_normal',\n","                   activation='softmax', name='output')(x)\n","\n","    model = Model(input=main_input, output=output)\n","\n","    print(model.summary())\n","    return model\n","\n","def build_stacked_RNN_model_3():\n","    main_input = Input(shape=(maxlen, ), dtype='int32', name='main_input')\n","    embedding  = Embedding(max_features, embedding_dims,\n","                  weights=[embedding_matrix], input_length=maxlen,\n","                  name='embedding' ,trainable=False)(main_input)\n","\n","    embedding = Dropout(0.50)(embedding)\n","\n","    x = RNN(rnn_output_size,return_sequences=True)(embedding)\n","    x = RNN(rnn_output_size,return_sequences=True)(x)\n","    x = RNN(rnn_output_size)(x)\n","\n","    x = Dense(hidden_dims, activation='relu', init='he_normal',\n","              W_constraint = maxnorm(3), b_constraint=maxnorm(3),\n","              name='mlp')(x)\n","\n","    x = Dropout(0.10, name='drop')(x)\n","\n","    output = Dense(4, init='he_normal',\n","                   activation='softmax', name='output')(x)\n","\n","    model = Model(input=main_input, output=output)\n","\n","    print(model.summary())\n","    return model"],"execution_count":70,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Pt3TZsP84gRK"},"source":["## CNN+RNN(LSTM /GRU) model "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"m3v2boPz4frA","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725599,"user_tz":-330,"elapsed":4066,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["def build_CNN_RNN_model():\n","    main_input = Input(shape=(maxlen, ), dtype='int32', name='main_input')\n","    embedding  = Embedding(max_features, embedding_dims,\n","                  weights=[embedding_matrix], input_length=maxlen,\n","                  name='embedding' ,trainable=False)(main_input)\n","\n","    embedding = Dropout(0.50)(embedding)\n","\n","    conv4 = Convolution1D(nb_filter=nb_filter,\n","                          filter_length=4,\n","                          border_mode='valid',\n","                          activation='relu',\n","                          subsample_length=1,\n","                          name='conv4')(embedding)\n","    maxConv4 = MaxPooling1D(pool_length=2,\n","                             name='maxConv4')(conv4)\n","\n","    conv5 = Convolution1D(nb_filter=nb_filter,\n","                          filter_length=5,\n","                          border_mode='valid',\n","                          activation='relu',\n","                          subsample_length=1,\n","                          name='conv5')(embedding)\n","    maxConv5 = MaxPooling1D(pool_length=2,\n","                            name='maxConv5')(conv5)\n","\n","    x = keras.layers.Concatenate(axis=1)([maxConv4, maxConv5])\n","\n","    x = Dropout(0.15)(x)\n","\n","    x = RNN(rnn_output_size)(x)\n","\n","\n","    x = Dense(hidden_dims, activation='relu', init='he_normal',\n","              W_constraint = maxnorm(3), b_constraint=maxnorm(3),\n","              name='mlp')(x)\n","\n","    x = Dropout(0.10, name='drop')(x)\n","\n","    output = Dense(4, init='he_normal',\n","                   activation='softmax', name='output')(x)\n","\n","    model = Model(input=main_input, output=output)\n","\n","    return model"],"execution_count":71,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"P5nll2IhjLhr"},"source":["## BiLSTM "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GMs9GE8Dlpiw","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725600,"user_tz":-330,"elapsed":4053,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["# final model\n","def build_BiLSTM_1_2():\n","  input = Input(shape=(maxlen,))\n","  embedding = Embedding(max_features,embedding_dims,weights=[embedding_matrix],input_length=maxlen)(input)\n","\n","  model =  Bidirectional (LSTM (300,return_sequences=True,dropout=drop_out_value,kernel_regularizer=l2(0.01)),merge_mode='concat')(embedding)\n","  model = TimeDistributed(Dense(300,activation='relu'))(model)\n","  model = Flatten()(model)\n","  model = Dense(300,activation='relu')(model) # extra dense layer\n","  output = Dense(4,activation='softmax')(model)\n","  model = Model(input,output)\n","  \n","  return model\n","\n","def build_BiLSTM_plain():\n","  input = Input(shape=(maxlen,))\n","  embedding = Embedding(max_features,embedding_dims,weights=[embedding_matrix],input_length=maxlen)(input)\n","\n","  model =  Bidirectional (LSTM (300,return_sequences=True),merge_mode='concat')(embedding)\n","  model = TimeDistributed(Dense(300,activation='relu'))(model)\n","  model = Flatten()(model)\n","  model = Dense(300,activation='relu')(model) # extra dense layer\n","  output = Dense(4,activation='softmax')(model)\n","  model = Model(input,output)\n","  \n","  return model"],"execution_count":72,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m4yXL4a2skYE","colab_type":"text"},"source":["### Stacked_BiLSTM"]},{"cell_type":"code","metadata":{"id":"5sHM1tbTsolw","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725601,"user_tz":-330,"elapsed":4030,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["# final model\n","def build_Stacked_BiLSTM_2():\n","  input = Input(shape=(maxlen,))\n","  embedding = Embedding(max_features,embedding_dims,weights=[embedding_matrix],input_length=maxlen)(input)\n","\n","  model =  Bidirectional (LSTM (300,return_sequences=True,dropout=drop_out_value,kernel_regularizer=l2(0.01)),merge_mode='concat')(embedding)\n","  model =  Bidirectional (LSTM (300,return_sequences=True),merge_mode='concat')(model)\n","  model = TimeDistributed(Dense(300,activation='relu'))(model)\n","  model = Flatten()(model)\n","  model = Dense(300,activation='relu')(model)\n","  output = Dense(4,activation='softmax')(model)\n","  model = Model(input,output)\n","  \n","  return model\n","\n","# final model\n","def build_Stacked_BiLSTM_3():\n","  input = Input(shape=(maxlen,))\n","  embedding = Embedding(max_features,embedding_dims,weights=[embedding_matrix],input_length=maxlen)(input)\n","\n","  model =  Bidirectional (LSTM (300,return_sequences=True,dropout=drop_out_value,kernel_regularizer=l2(0.01)),merge_mode='concat')(embedding)\n","  model =  Bidirectional (LSTM (300,return_sequences=True),merge_mode='concat')(model)\n","  model =  Bidirectional (LSTM (300,return_sequences=True),merge_mode='concat')(model)\n","  model = TimeDistributed(Dense(300,activation='relu'))(model)\n","  model = Flatten()(model)\n","  model = Dense(300,activation='relu')(model)\n","  output = Dense(4,activation='softmax')(model)\n","  model = Model(input,output)\n","  \n","  return model"],"execution_count":73,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"k7QWHo7RBFYw"},"source":["## CNN+BiLSTM"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"W3yWVn8nB2Q6","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725601,"user_tz":-330,"elapsed":4014,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["def build_CNN_BiLSTM():\n","  # main model\n","  input = Input(shape=(maxlen,))\n","  embedding = Embedding(max_features,300,weights=[embedding_matrix],input_length=maxlen)(input)\n","\n","  conv4 = Convolution1D(nb_filter=nb_filter,\n","                          filter_length=4,\n","                          border_mode='valid',\n","                          activation='relu',\n","                          subsample_length=1,\n","                          name='conv4')(embedding)\n","  maxConv4 = MaxPooling1D(pool_length=2,\n","                             name='maxConv4')(conv4)\n","\n","  conv5 = Convolution1D(nb_filter=nb_filter,\n","                          filter_length=5,\n","                          border_mode='valid',\n","                          activation='relu',\n","                          subsample_length=1,\n","                          name='conv5')(embedding)\n","  maxConv5 = MaxPooling1D(pool_length=2,\n","                            name='maxConv5')(conv5)\n","\n","\n","  x = keras.layers.Concatenate(axis=1)([maxConv4, maxConv5])\n","\n","  x = Dropout(0.15)(x)\n","\n","  model =  Bidirectional (LSTM (300,return_sequences=True,dropout=0.8),merge_mode='concat')(x)\n","  model = TimeDistributed(Dense(300,activation='relu'))(model)\n","  model = Flatten()(model)\n","  model = Dense(300,activation='relu')(model)\n","  output = Dense(4,activation='softmax')(model)\n","  model = Model(input,output)\n","  \n","  return model\n"],"execution_count":74,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WC0ZRhKe5a6C"},"source":["# Train and Evaluate Model"]},{"cell_type":"markdown","metadata":{"id":"jbpLZfOPGGKN","colab_type":"text"},"source":["## Custom F1 Implementation"]},{"cell_type":"code","metadata":{"id":"O0sMLlLvEGKq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725602,"user_tz":-330,"elapsed":3993,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["def f1(y_true, y_pred):\n","    def recall(y_true, y_pred):\n","        \"\"\"Recall metric.\n","\n","        Only computes a batch-wise average of recall.\n","\n","        Computes the recall, a metric for multi-label classification of\n","        how many relevant items are selected.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n","        recall = true_positives / (possible_positives + K.epsilon())\n","        return recall\n","\n","    def precision(y_true, y_pred):\n","        \"\"\"Precision metric.\n","\n","        Only computes a batch-wise average of precision.\n","\n","        Computes the precision, a metric for multi-label classification of\n","        how many selected items are relevant.\n","        \"\"\"\n","        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n","        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n","        precision = true_positives / (predicted_positives + K.epsilon())\n","        return precision\n","    precision = precision(y_true, y_pred)\n","    recall = recall(y_true, y_pred)\n","    return 2*((precision*recall)/(precision+recall+K.epsilon()))"],"execution_count":75,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fqK6yZoCHIyE","colab_type":"text"},"source":["## Train and Validate model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LhOLwIC-5aiD","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725603,"user_tz":-330,"elapsed":3964,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["def Train_Model_old(model,X_train, X_test, y_train, y_test):\n","\n","  print('Training and Testing...')\n","  test_accs = []\n","  first_run = True\n","\n","\n","  acc=[]\n","  val_acc=[]\n","  loss=[]\n","  val_loss=[]\n","  best_val_acc = 0\n","  best_test_acc = 0\n","  for j in range(nb_epoch):\n","      a = time.time()\n","      his = model.fit(X_train, y_train,\n","                      batch_size=batch_size,\n","                      validation_data=[X_test, y_test],\n","                      shuffle=True,\n","                      epochs=1, verbose=verbosity)\n","      acc+=his.history['accuracy']\n","      val_acc+=his.history['val_accuracy']\n","      loss+=his.history['loss']\n","      val_loss+=his.history['val_loss']\n","      # print('Epoch %d/%d\\t%s' % (j + 1, nb_epoch, str(his.history)))\n","      if his.history['val_accuracy'][0] >= best_val_acc:\n","          score, test_acc = model.evaluate(X_test, y_test,\n","                                      batch_size=batch_size,\n","                                      verbose=2)\n","          best_val_acc = his.history['val_accuracy'][0]\n","          best_test_acc = test_acc\n","          print('Got best epoch  best val acc is %f test acc is %f' %\n","                (best_val_acc, best_test_acc))\n","          if len(test_accs) > 0:\n","              print('Current avg test acc:', str(np.mean(test_accs)))\n","      b = time.time()\n","      cost = b - a\n","      left = (nb_epoch - j - 1)\n","      print('One round cost %ds, %d round %ds %dmin left' % (cost, left,\n","                                                            cost * left,\n","                                                            cost * left / 60.0))\n","      test_accs.append(best_test_acc)\n","\n","  print('Avg test acc:', str(np.mean(test_accs)))\n","  return model"],"execution_count":76,"outputs":[]},{"cell_type":"code","metadata":{"id":"XTuRxzncQc5q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725604,"user_tz":-330,"elapsed":3938,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["def Train_Model(model,X_train, y_train, cross_validation = False):\n","\n","  print('Training and Testing...')\n","  \n","  es = EarlyStopping(monitor='val_f1', mode='max', verbose=1, patience=3)\n","  checkpoint = ModelCheckpoint(model_save_path, monitor='val_f1', verbose=1, save_best_only=True, mode='max')\n","  callbacks_list = [checkpoint,es]\n","\n","  if (cross_validation):\n","    callbacks_list = [es]\n","\n","  his = model.fit(X_train, y_train, validation_split=validation_split, epochs=nb_epoch, batch_size=batch_size, callbacks=callbacks_list, verbose=1)\n","  return model,his"],"execution_count":77,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9bLlGFRYHOLD","colab_type":"text"},"source":["Compile Model"]},{"cell_type":"code","metadata":{"id":"_o50fP0fZZMr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725604,"user_tz":-330,"elapsed":3916,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["def compile_model(model , model_type):\n","  if model_type ==  1: # CNN RNN GRU LSTM \n","    model.compile(loss={'output':'categorical_crossentropy'},\n","                  optimizer=Adadelta(lr=0.95, epsilon=1e-06),\n","                  metrics=[\"accuracy\",f1])\n","  elif model_type == 2 :# CNN BiLSTM \n","    model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy',f1])\n","  return model"],"execution_count":78,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u4DuyDZMkcE3"},"source":["# Cross Validation"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4TMmqz8BkTQR","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725605,"user_tz":-330,"elapsed":3896,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["def Do_Cross_Validation(model,X,y):\n","\n","  # Define per-fold score containers\n","  acc_per_fold = []\n","  loss_per_fold = []\n","  f1_per_fold = []\n","\n","  kfold = KFold(n_splits=folds, shuffle=True)\n","\n","  fold_no = 1\n","  inputs = X\n","  targets = y\n","  for train, test in kfold.split(inputs, targets):\n","\n","    # Generate a print\n","    print('------------------------------------------------------------------------')\n","    print(f'Training for fold {fold_no} ...')\n","\n","    # Fit data to model\n","    model, his = Train_Model(model,inputs[train], targets[train], cross_validation=True)\n"," \n","    # Generate generalization metrics\n","    scores = model.evaluate(inputs[test], targets[test], verbose=0)\n","    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}% ; {model.metrics_names[2]} of {scores[2]*100}%')\n","    loss_per_fold.append(scores[0])\n","    acc_per_fold.append(scores[1]*100)\n","    f1_per_fold.append(scores[1]*100)\n","\n","    # Increase fold number\n","    fold_no = fold_no + 1\n","\n","  # == Provide average scores ==\n","  print('------------------------------------------------------------------------')\n","  print('Score per fold')\n","  for i in range(0, len(acc_per_fold)):\n","    print('------------------------------------------------------------------------')\n","    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}% - F1: {f1_per_fold[i]}%')\n","  print('------------------------------------------------------------------------')\n","  print('Average scores for all folds:')\n","  print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n","  print(f'> Loss: {np.mean(loss_per_fold)}')\n","  print(f'> F1: {np.mean(f1_per_fold)}')\n","  print('------------------------------------------------------------------------')"],"execution_count":79,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"B6CXqtIDR4jS"},"source":["# Plot Graphs"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"fvl487sr8seD","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725606,"user_tz":-330,"elapsed":3870,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["def Plot_graphs(metric,val_metric,metric_name):\n","\n","  epochs=range(len(metric)) # Get number of epochs\n","\n","  if metric_name == \"accuracy\":\n","    #------------------------------------------------\n","    # Plot training and validation accuracy per epoch\n","    #------------------------------------------------\n","    plt.plot(epochs, metric, 'r')\n","    plt.plot(epochs, val_metric, 'b')\n","    plt.title('Training and validation accuracy')\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"Accuracy\")\n","    plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n","\n","    plt.figure()\n","\n","  elif metric_name == \"loss\" :\n","    #------------------------------------------------\n","    # Plot training and validation loss per epoch\n","    #------------------------------------------------\n","    plt.plot(epochs, metric, 'r')\n","    plt.plot(epochs, val_metric, 'b')\n","    plt.title('Training and validation loss')\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend([\"Loss\", \"Validation Loss\"])\n","\n","    plt.figure()\n","\n","  elif metric_name == \"f1\" :\n","    #------------------------------------------------\n","    # Plot training and validation loss per epoch\n","    #------------------------------------------------\n","    plt.plot(epochs, metric, 'r')\n","    plt.plot(epochs, val_metric, 'b')\n","    plt.title('Training and validation F1')\n","    plt.xlabel(\"Epochs\")\n","    plt.ylabel(\"F1\")\n","    plt.legend([\"F1\", \"Validation F1\"])\n","\n","    plt.figure()\n","\n","\n","  # Expected Output\n","  # A chart where the validation loss does not increase sharply!"],"execution_count":80,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0RS6GyZ8-mk7"},"source":["# Main Method"]},{"cell_type":"markdown","metadata":{"id":"dN_uGz3CZMCh","colab_type":"text"},"source":["## Set Parameters"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"85wsS8Mn8oeI","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725607,"user_tz":-330,"elapsed":3847,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["# embedding_matrix = generate_embedding_metrix()\n","embedding_matrix = load_word_embedding_atrix()"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uueiXUkkWuKl","colab":{},"executionInfo":{"status":"ok","timestamp":1596261725608,"user_tz":-330,"elapsed":3833,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["batch_size = 32 # 64, 128\n","nb_filter = 200\n","filter_length = 4 # test with 2,3,4,5\n","hidden_dims = nb_filter * 2\n","nb_epoch = 15\n","RNN = LSTM\n","rnn_output_size = embedding_size \n","folds = 10\n","maxlen = 210 #test with other values\n","max_features = embedding_matrix.shape[0] #vocab_size\n","embedding_dims = embedding_size\n","drop_out_value = 0.5 #0.8 #0.3\n","verbosity = 1\n","validation_split = 0.2"],"execution_count":82,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R-a_TJZwtD9A","colab_type":"text"},"source":["## Build and Compile Model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4PBWe0V1-mK1","colab":{"base_uri":"https://localhost:8080/","height":496},"executionInfo":{"status":"ok","timestamp":1596261726100,"user_tz":-330,"elapsed":4310,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}},"outputId":"c9fc8d35-ce24-41d4-f490-72fc20246077"},"source":["model = build_RNN_model()"],"execution_count":83,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","main_input (InputLayer)      (None, 210)               0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, 210, 300)          18094800  \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 210, 300)          0         \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 300)               721200    \n","_________________________________________________________________\n","mlp (Dense)                  (None, 400)               120400    \n","_________________________________________________________________\n","drop (Dropout)               (None, 400)               0         \n","_________________________________________________________________\n","output (Dense)               (None, 4)                 1604      \n","=================================================================\n","Total params: 18,938,004\n","Trainable params: 843,204\n","Non-trainable params: 18,094,800\n","_________________________________________________________________\n","None\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(400, activation=\"relu\", name=\"mlp\", kernel_initializer=\"he_normal\", kernel_constraint=<keras.con..., bias_constraint=<keras.con...)`\n","  del sys.path[0]\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, activation=\"softmax\", name=\"output\", kernel_initializer=\"he_normal\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"ma..., outputs=Tensor(\"ou...)`\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eMA3XMXFSj-1","colab":{},"executionInfo":{"status":"ok","timestamp":1596261726102,"user_tz":-330,"elapsed":4300,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["# model_type = 1 => CNN RNN GRU LSTM\n","# model_type = 2 => CNN BiLSTM\n","trained_model = compile_model(model, 2)"],"execution_count":84,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d46ja9NetIpP","colab_type":"text"},"source":["## Train and Test Model (Holdout Method)"]},{"cell_type":"code","metadata":{"id":"ye7IkwWamR2c","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596261726103,"user_tz":-330,"elapsed":4284,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}}},"source":["# trained_model = Train_Model_1(model,X_train, X_test, y_train, y_test)\n","# trained_model, his = Train_Model_2(trained_model,X_train, y_train)\n","\n","# accuracy = his.history['accuracy']\n","# val_accuracy = his.history['val_accuracy']\n","# loss = his.history['loss']\n","# val_loss = his.history['val_loss']\n","# f1 = his.history['f1']\n","# val_f1 = his.history['f1']\n","\n","# Plot_graphs(accuracy,val_accuracy, \"accuracy\")\n","# Plot_graphs(loss,val_loss, \"loss\")\n","# Plot_graphs(f1,val_f1, \"f1\")"],"execution_count":85,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H-RSSqI7BDqE","colab_type":"text"},"source":["### Restart runtime and import Relibraries\n","There is a bug, if run time isn't restart after this point, It's going to malfunction."]},{"cell_type":"code","metadata":{"id":"AnfxE-LmAWmK","colab_type":"code","colab":{}},"source":["# # os.kill(os.getpid(), 9)\n","\n","# exit()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cxp9ViDsA2bb","colab_type":"code","colab":{}},"source":["# from keras.models import Sequential,Model,load_model\n","# import pandas as pd\n","# import numpy as np\n","# from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix,precision_recall_fscore_support\n","\n","# experiment_no = 100\n","# model_name = \"RNN\"\n","# experiment_name = folder_path + \"Sentiment Analysis/CNN RNN/experiments/\" + model_name +str(experiment_no)+\"_\"+embedding_type+\"_\"+str(embedding_size)+\"_\"+str(context)\n","\n","# model_save_path = folder_path + \"Sentiment Analysis/CNN RNN/saved_models/weights_best_\"+model_name+\"_\"+embedding_type+\"_\"+str(embedding_size)+\"_\"+str(experiment_no)+\".hdf5\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_VdzOT3zsB9m","colab_type":"text"},"source":["### Test Model"]},{"cell_type":"markdown","metadata":{"id":"KMtXKRpRYBx2","colab_type":"text"},"source":["#### Load Weights to Model"]},{"cell_type":"code","metadata":{"id":"Yl7JuOSe3tBl","colab_type":"code","colab":{}},"source":["loaded_model  = load_model(model_save_path,custom_objects={\"f1\": f1}, compile=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W26LpD_NzEa-","colab_type":"text"},"source":["#### check loaded model"]},{"cell_type":"code","metadata":{"id":"Ed-z3F323si8","colab_type":"code","colab":{}},"source":["# _, train_acc,train_f1 = loaded_model.evaluate(X_train, y_train, verbose=1)\n","# _, test_acc,test_f1= loaded_model.evaluate(X_test, y_test, verbose=1)\n","# print('Train_acc: %.3f, Test_acc: %.3f, Train_f1: %.3f,  Test_f1: %.3f' % (train_acc, test_acc,train_f1,test_f1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BtZBU5XNZaMi","colab_type":"text"},"source":["#### Get Predictions"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MmA4iDmR2czB","colab":{}},"source":["predictions = loaded_model.predict(X_test, batch_size=batch_size, verbose=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"aUyKF-x010CH","colab":{}},"source":["labels = np.argmax(y_test, axis=1)\n","predictions = np.argmax(predictions, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kVeL03f-xkM4","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1595312683835,"user_tz":-330,"elapsed":22468,"user":{"displayName":"Lahiru Senevirathne","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiRzF3KfxeuLmDoDB90oNXQ5_ivLn8-Ar4kecdc=s64","userId":"12627549003426465017"}},"outputId":"37e49360-efe2-4c0a-8e45-75d2f998c045"},"source":["report = classification_report(labels, predictions, digits=4,output_dict=True)\n","report_print = classification_report(labels, predictions, digits=4)\n","print(report_print)\n","report_df = pd.DataFrame(report).transpose()\n","report_df.to_csv(experiment_name+\".csv\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0     0.6373    0.9263    0.7551      1533\n","           1     0.5127    0.2000    0.2877       505\n","           2     0.7761    0.6051    0.6800       590\n","           3     0.4094    0.1354    0.2035       384\n","\n","    accuracy                         0.6408      3012\n","   macro avg     0.5839    0.4667    0.4816      3012\n","weighted avg     0.6146    0.6408    0.5917      3012\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_-x34NEZtU5C","colab_type":"text"},"source":["## Train and Test Model (Cross Validation)"]},{"cell_type":"code","metadata":{"id":"2iZDvr80VxPN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596267247804,"user_tz":-330,"elapsed":32872,"user":{"displayName":"dataPirates fyp","photoUrl":"","userId":"14020399926305222994"}},"outputId":"d701611a-fa66-472d-8564-eff58e40e89d"},"source":["# Do_Cross_Validation(model,padded_docs,comment_labels)\n","Do_Cross_Validation(model,padded_docs,comment_labels)"],"execution_count":86,"outputs":[{"output_type":"stream","text":["------------------------------------------------------------------------\n","Training for fold 1 ...\n","Training and Testing...\n","Train on 10842 samples, validate on 2711 samples\n","Epoch 1/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 1.0018 - accuracy: 0.6045 - f1: 0.5459 - val_loss: 1.0472 - val_accuracy: 0.6053 - val_f1: 0.6052\n","\n","Epoch 00001: val_f1 improved from -inf to 0.60519, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 2/15\n","10842/10842 [==============================] - 107s 10ms/step - loss: 0.9213 - accuracy: 0.6386 - f1: 0.6022 - val_loss: 0.9433 - val_accuracy: 0.6153 - val_f1: 0.6132\n","\n","Epoch 00002: val_f1 improved from 0.60519 to 0.61323, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 3/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.8880 - accuracy: 0.6458 - f1: 0.6191 - val_loss: 0.9943 - val_accuracy: 0.6182 - val_f1: 0.5492\n","\n","Epoch 00003: val_f1 did not improve from 0.61323\n","Epoch 4/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.8589 - accuracy: 0.6535 - f1: 0.6284 - val_loss: 0.9121 - val_accuracy: 0.6352 - val_f1: 0.5877\n","\n","Epoch 00004: val_f1 did not improve from 0.61323\n","Epoch 5/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.8307 - accuracy: 0.6645 - f1: 0.6371 - val_loss: 0.9840 - val_accuracy: 0.6042 - val_f1: 0.5330\n","\n","Epoch 00005: val_f1 did not improve from 0.61323\n","Epoch 00005: early stopping\n","Score for fold 1: loss of 0.9638896161024947; accuracy of 60.424965620040894% ; f1 of 51.84880495071411%\n","------------------------------------------------------------------------\n","Training for fold 2 ...\n","Training and Testing...\n","Train on 10842 samples, validate on 2711 samples\n","Epoch 1/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.8225 - accuracy: 0.6716 - f1: 0.6460 - val_loss: 0.8874 - val_accuracy: 0.6363 - val_f1: 0.6202\n","\n","Epoch 00001: val_f1 improved from -inf to 0.62018, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 2/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.7861 - accuracy: 0.6806 - f1: 0.6638 - val_loss: 0.9406 - val_accuracy: 0.6356 - val_f1: 0.6212\n","\n","Epoch 00002: val_f1 improved from 0.62018 to 0.62123, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 3/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.7498 - accuracy: 0.7009 - f1: 0.6782 - val_loss: 0.9814 - val_accuracy: 0.6389 - val_f1: 0.6093\n","\n","Epoch 00003: val_f1 did not improve from 0.62123\n","Epoch 4/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.7109 - accuracy: 0.7124 - f1: 0.6980 - val_loss: 1.0471 - val_accuracy: 0.6252 - val_f1: 0.6185\n","\n","Epoch 00004: val_f1 did not improve from 0.62123\n","Epoch 5/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.6671 - accuracy: 0.7305 - f1: 0.7174 - val_loss: 1.0702 - val_accuracy: 0.6282 - val_f1: 0.6229\n","\n","Epoch 00005: val_f1 improved from 0.62123 to 0.62288, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 6/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.6071 - accuracy: 0.7548 - f1: 0.7482 - val_loss: 1.1368 - val_accuracy: 0.6260 - val_f1: 0.6199\n","\n","Epoch 00006: val_f1 did not improve from 0.62288\n","Epoch 7/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.5563 - accuracy: 0.7802 - f1: 0.7696 - val_loss: 1.1341 - val_accuracy: 0.6072 - val_f1: 0.5923\n","\n","Epoch 00007: val_f1 did not improve from 0.62288\n","Epoch 8/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.5245 - accuracy: 0.7938 - f1: 0.7907 - val_loss: 1.0903 - val_accuracy: 0.6149 - val_f1: 0.5978\n","\n","Epoch 00008: val_f1 did not improve from 0.62288\n","Epoch 00008: early stopping\n","Score for fold 2: loss of 0.9358672256647037; accuracy of 65.8698558807373% ; f1 of 63.503313064575195%\n","------------------------------------------------------------------------\n","Training for fold 3 ...\n","Training and Testing...\n","Train on 10842 samples, validate on 2711 samples\n","Epoch 1/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.5348 - accuracy: 0.7923 - f1: 0.7861 - val_loss: 1.1707 - val_accuracy: 0.6127 - val_f1: 0.6078\n","\n","Epoch 00001: val_f1 improved from -inf to 0.60776, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 2/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.4685 - accuracy: 0.8178 - f1: 0.8143 - val_loss: 1.2022 - val_accuracy: 0.5946 - val_f1: 0.5901\n","\n","Epoch 00002: val_f1 did not improve from 0.60776\n","Epoch 3/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.4272 - accuracy: 0.8339 - f1: 0.8317 - val_loss: 1.4955 - val_accuracy: 0.6079 - val_f1: 0.6065\n","\n","Epoch 00003: val_f1 did not improve from 0.60776\n","Epoch 4/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.3866 - accuracy: 0.8488 - f1: 0.8480 - val_loss: 1.3538 - val_accuracy: 0.6083 - val_f1: 0.6030\n","\n","Epoch 00004: val_f1 did not improve from 0.60776\n","Epoch 00004: early stopping\n","Score for fold 3: loss of 0.5414393407256797; accuracy of 81.00929856300354% ; f1 of 80.60417771339417%\n","------------------------------------------------------------------------\n","Training for fold 4 ...\n","Training and Testing...\n","Train on 10842 samples, validate on 2711 samples\n","Epoch 1/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.3846 - accuracy: 0.8554 - f1: 0.8545 - val_loss: 1.4415 - val_accuracy: 0.5865 - val_f1: 0.5805\n","\n","Epoch 00001: val_f1 improved from -inf to 0.58052, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 2/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.3458 - accuracy: 0.8701 - f1: 0.8697 - val_loss: 1.3563 - val_accuracy: 0.5869 - val_f1: 0.5831\n","\n","Epoch 00002: val_f1 improved from 0.58052 to 0.58315, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 3/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.3098 - accuracy: 0.8822 - f1: 0.8825 - val_loss: 1.5610 - val_accuracy: 0.5887 - val_f1: 0.5836\n","\n","Epoch 00003: val_f1 improved from 0.58315 to 0.58358, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 4/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.4559 - accuracy: 0.8286 - f1: 0.8255 - val_loss: 1.4317 - val_accuracy: 0.6153 - val_f1: 0.6142\n","\n","Epoch 00004: val_f1 improved from 0.58358 to 0.61423, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 5/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.3112 - accuracy: 0.8783 - f1: 0.8776 - val_loss: 1.6420 - val_accuracy: 0.6064 - val_f1: 0.6069\n","\n","Epoch 00005: val_f1 did not improve from 0.61423\n","Epoch 6/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.2745 - accuracy: 0.8953 - f1: 0.8953 - val_loss: 1.6073 - val_accuracy: 0.6072 - val_f1: 0.6041\n","\n","Epoch 00006: val_f1 did not improve from 0.61423\n","Epoch 7/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.2367 - accuracy: 0.9120 - f1: 0.9122 - val_loss: 1.8879 - val_accuracy: 0.5692 - val_f1: 0.5693\n","\n","Epoch 00007: val_f1 did not improve from 0.61423\n","Epoch 00007: early stopping\n","Score for fold 4: loss of 0.6444741588823032; accuracy of 82.20451474189758% ; f1 of 81.58071041107178%\n","------------------------------------------------------------------------\n","Training for fold 5 ...\n","Training and Testing...\n","Train on 10842 samples, validate on 2711 samples\n","Epoch 1/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.2768 - accuracy: 0.8984 - f1: 0.8974 - val_loss: 1.8579 - val_accuracy: 0.6260 - val_f1: 0.6240\n","\n","Epoch 00001: val_f1 improved from -inf to 0.62400, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 2/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.2451 - accuracy: 0.9062 - f1: 0.9061 - val_loss: 1.8989 - val_accuracy: 0.5976 - val_f1: 0.5961\n","\n","Epoch 00002: val_f1 did not improve from 0.62400\n","Epoch 3/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.2362 - accuracy: 0.9116 - f1: 0.9117 - val_loss: 1.7575 - val_accuracy: 0.6035 - val_f1: 0.6017\n","\n","Epoch 00003: val_f1 did not improve from 0.62400\n","Epoch 4/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.2183 - accuracy: 0.9204 - f1: 0.9207 - val_loss: 1.9174 - val_accuracy: 0.6046 - val_f1: 0.6024\n","\n","Epoch 00004: val_f1 did not improve from 0.62400\n","Epoch 00004: early stopping\n","Score for fold 5: loss of 0.4484646301345521; accuracy of 89.9734377861023% ; f1 of 88.29537034034729%\n","------------------------------------------------------------------------\n","Training for fold 6 ...\n","Training and Testing...\n","Train on 10842 samples, validate on 2711 samples\n","Epoch 1/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.2265 - accuracy: 0.9171 - f1: 0.9150 - val_loss: 1.7894 - val_accuracy: 0.5662 - val_f1: 0.5651\n","\n","Epoch 00001: val_f1 improved from -inf to 0.56513, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 2/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.2143 - accuracy: 0.9208 - f1: 0.9204 - val_loss: 1.7212 - val_accuracy: 0.6094 - val_f1: 0.6067\n","\n","Epoch 00002: val_f1 improved from 0.56513 to 0.60674, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 3/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.1998 - accuracy: 0.9258 - f1: 0.9256 - val_loss: 1.9527 - val_accuracy: 0.5784 - val_f1: 0.5748\n","\n","Epoch 00003: val_f1 did not improve from 0.60674\n","Epoch 4/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.1871 - accuracy: 0.9311 - f1: 0.9308 - val_loss: 1.9128 - val_accuracy: 0.6042 - val_f1: 0.6037\n","\n","Epoch 00004: val_f1 did not improve from 0.60674\n","Epoch 5/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.1822 - accuracy: 0.9322 - f1: 0.9328 - val_loss: 1.8596 - val_accuracy: 0.5854 - val_f1: 0.5830\n","\n","Epoch 00005: val_f1 did not improve from 0.60674\n","Epoch 00005: early stopping\n","Score for fold 6: loss of 0.3339019811762915; accuracy of 92.36387610435486% ; f1 of 92.46973395347595%\n","------------------------------------------------------------------------\n","Training for fold 7 ...\n","Training and Testing...\n","Train on 10842 samples, validate on 2711 samples\n","Epoch 1/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.1980 - accuracy: 0.9280 - f1: 0.9276 - val_loss: 1.7758 - val_accuracy: 0.6131 - val_f1: 0.6111\n","\n","Epoch 00001: val_f1 improved from -inf to 0.61115, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 2/15\n","10842/10842 [==============================] - 107s 10ms/step - loss: 0.1755 - accuracy: 0.9349 - f1: 0.9347 - val_loss: 1.8817 - val_accuracy: 0.6108 - val_f1: 0.6105\n","\n","Epoch 00002: val_f1 did not improve from 0.61115\n","Epoch 3/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.1736 - accuracy: 0.9353 - f1: 0.9360 - val_loss: 2.0413 - val_accuracy: 0.6094 - val_f1: 0.6093\n","\n","Epoch 00003: val_f1 did not improve from 0.61115\n","Epoch 4/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.1738 - accuracy: 0.9391 - f1: 0.9393 - val_loss: 1.8596 - val_accuracy: 0.6038 - val_f1: 0.6014\n","\n","Epoch 00004: val_f1 did not improve from 0.61115\n","Epoch 00004: early stopping\n","Score for fold 7: loss of 0.39224393233399624; accuracy of 92.1646773815155% ; f1 of 90.26708006858826%\n","------------------------------------------------------------------------\n","Training for fold 8 ...\n","Training and Testing...\n","Train on 10842 samples, validate on 2711 samples\n","Epoch 1/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.1713 - accuracy: 0.9370 - f1: 0.9369 - val_loss: 2.0252 - val_accuracy: 0.6013 - val_f1: 0.5975\n","\n","Epoch 00001: val_f1 improved from -inf to 0.59752, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 2/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.1629 - accuracy: 0.9423 - f1: 0.9423 - val_loss: 1.9690 - val_accuracy: 0.6149 - val_f1: 0.6123\n","\n","Epoch 00002: val_f1 improved from 0.59752 to 0.61227, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 3/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.1533 - accuracy: 0.9431 - f1: 0.9429 - val_loss: 1.9348 - val_accuracy: 0.6027 - val_f1: 0.6014\n","\n","Epoch 00003: val_f1 did not improve from 0.61227\n","Epoch 4/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.1561 - accuracy: 0.9412 - f1: 0.9419 - val_loss: 2.0327 - val_accuracy: 0.5990 - val_f1: 0.5970\n","\n","Epoch 00004: val_f1 did not improve from 0.61227\n","Epoch 5/15\n","10842/10842 [==============================] - 105s 10ms/step - loss: 0.1468 - accuracy: 0.9473 - f1: 0.9472 - val_loss: 2.1988 - val_accuracy: 0.6120 - val_f1: 0.6114\n","\n","Epoch 00005: val_f1 did not improve from 0.61227\n","Epoch 00005: early stopping\n","Score for fold 8: loss of 0.47016833132382724; accuracy of 91.03585481643677% ; f1 of 90.28980731964111%\n","------------------------------------------------------------------------\n","Training for fold 9 ...\n","Training and Testing...\n","Train on 10842 samples, validate on 2711 samples\n","Epoch 1/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.1603 - accuracy: 0.9407 - f1: 0.9412 - val_loss: 1.8859 - val_accuracy: 0.5780 - val_f1: 0.5750\n","\n","Epoch 00001: val_f1 improved from -inf to 0.57502, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 2/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.1499 - accuracy: 0.9452 - f1: 0.9455 - val_loss: 2.1289 - val_accuracy: 0.5858 - val_f1: 0.5828\n","\n","Epoch 00002: val_f1 improved from 0.57502 to 0.58281, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 3/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.1426 - accuracy: 0.9471 - f1: 0.9468 - val_loss: 1.9652 - val_accuracy: 0.6182 - val_f1: 0.6185\n","\n","Epoch 00003: val_f1 improved from 0.58281 to 0.61853, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 4/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.1457 - accuracy: 0.9479 - f1: 0.9476 - val_loss: 2.2482 - val_accuracy: 0.6182 - val_f1: 0.6161\n","\n","Epoch 00004: val_f1 did not improve from 0.61853\n","Epoch 5/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.1307 - accuracy: 0.9524 - f1: 0.9521 - val_loss: 2.2017 - val_accuracy: 0.6060 - val_f1: 0.6063\n","\n","Epoch 00005: val_f1 did not improve from 0.61853\n","Epoch 6/15\n","10842/10842 [==============================] - 106s 10ms/step - loss: 0.1394 - accuracy: 0.9510 - f1: 0.9509 - val_loss: 2.1500 - val_accuracy: 0.5769 - val_f1: 0.5751\n","\n","Epoch 00006: val_f1 did not improve from 0.61853\n","Epoch 00006: early stopping\n","Score for fold 9: loss of 0.4642026284697205; accuracy of 91.83266758918762% ; f1 of 90.08040428161621%\n","------------------------------------------------------------------------\n","Training for fold 10 ...\n","Training and Testing...\n","Train on 10843 samples, validate on 2711 samples\n","Epoch 1/15\n","10843/10843 [==============================] - 106s 10ms/step - loss: 0.1346 - accuracy: 0.9512 - f1: 0.9513 - val_loss: 2.3423 - val_accuracy: 0.6120 - val_f1: 0.6127\n","\n","Epoch 00001: val_f1 improved from -inf to 0.61275, saving model to /content/drive/My Drive/FYP/Sentiment Analysis/Implementation/Sentiment Analysis/CNN RNN/saved_models/112_weights_best_\"stacked_LSTM_3\"_fasttext_112.hdf5\n","Epoch 2/15\n","10843/10843 [==============================] - 105s 10ms/step - loss: 0.1355 - accuracy: 0.9511 - f1: 0.9507 - val_loss: 2.2076 - val_accuracy: 0.6131 - val_f1: 0.6126\n","\n","Epoch 00002: val_f1 did not improve from 0.61275\n","Epoch 3/15\n","10843/10843 [==============================] - 105s 10ms/step - loss: 0.1297 - accuracy: 0.9533 - f1: 0.9532 - val_loss: 2.5573 - val_accuracy: 0.6105 - val_f1: 0.6095\n","\n","Epoch 00003: val_f1 did not improve from 0.61275\n","Epoch 4/15\n","10843/10843 [==============================] - 107s 10ms/step - loss: 0.1239 - accuracy: 0.9543 - f1: 0.9544 - val_loss: 2.3111 - val_accuracy: 0.5987 - val_f1: 0.5976\n","\n","Epoch 00004: val_f1 did not improve from 0.61275\n","Epoch 00004: early stopping\n","Score for fold 10: loss of 0.4604757124298187; accuracy of 91.82724356651306% ; f1 of 91.81694388389587%\n","------------------------------------------------------------------------\n","Score per fold\n","------------------------------------------------------------------------\n","> Fold 1 - Loss: 0.9638896161024947 - Accuracy: 60.424965620040894% - F1: 60.424965620040894%\n","------------------------------------------------------------------------\n","> Fold 2 - Loss: 0.9358672256647037 - Accuracy: 65.8698558807373% - F1: 65.8698558807373%\n","------------------------------------------------------------------------\n","> Fold 3 - Loss: 0.5414393407256797 - Accuracy: 81.00929856300354% - F1: 81.00929856300354%\n","------------------------------------------------------------------------\n","> Fold 4 - Loss: 0.6444741588823032 - Accuracy: 82.20451474189758% - F1: 82.20451474189758%\n","------------------------------------------------------------------------\n","> Fold 5 - Loss: 0.4484646301345521 - Accuracy: 89.9734377861023% - F1: 89.9734377861023%\n","------------------------------------------------------------------------\n","> Fold 6 - Loss: 0.3339019811762915 - Accuracy: 92.36387610435486% - F1: 92.36387610435486%\n","------------------------------------------------------------------------\n","> Fold 7 - Loss: 0.39224393233399624 - Accuracy: 92.1646773815155% - F1: 92.1646773815155%\n","------------------------------------------------------------------------\n","> Fold 8 - Loss: 0.47016833132382724 - Accuracy: 91.03585481643677% - F1: 91.03585481643677%\n","------------------------------------------------------------------------\n","> Fold 9 - Loss: 0.4642026284697205 - Accuracy: 91.83266758918762% - F1: 91.83266758918762%\n","------------------------------------------------------------------------\n","> Fold 10 - Loss: 0.4604757124298187 - Accuracy: 91.82724356651306% - F1: 91.82724356651306%\n","------------------------------------------------------------------------\n","Average scores for all folds:\n","> Accuracy: 83.87063920497894 (+- 11.13958306075138)\n","> Loss: 0.5655127557243388\n","> F1: 83.87063920497894\n","------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I-Y2Tyn4s2YG","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LR7WojLAszo7","colab_type":"text"},"source":["# Hyperparameter Tuning"]},{"cell_type":"code","metadata":{"id":"hIK_Zrdrulxg","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}